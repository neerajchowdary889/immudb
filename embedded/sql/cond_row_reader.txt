Approach for parallelizing conditional row filtering

1. Understand constraints
Thread safety: The underlying rowReader may not be safe for concurrent access.
Ordering: If ORDER BY is present, preserve row order.
Interface contract: Read() is sequential; parallelization must be internal.
Resource limits: Bound concurrency to avoid excessive goroutines.

2. Recommended pattern: buffered pipeline with worker pool
Architecture
Row Source → Buffer → Worker Pool (condition evaluation) → Result Queue → Sequential Read()
Components

A. Prefetch buffer
Use a channel or buffer to prefetch rows from the underlying reader.
Single goroutine reads from rowReader and enqueues rows.
Bounded buffer to control memory.

B. Worker pool
Fixed-size pool of workers (e.g., runtime.NumCPU() or configurable).
Each worker:
Takes a row from the buffer.
Substitutes parameters.
Evaluates the condition.
Enqueues results (row + boolean) to a results channel.

C. Result aggregator
Collects evaluated results.
If ordering matters, use a priority queue or sequence numbers to maintain order.
If ordering doesn’t matter, return results as they complete.

D. Sequential interface
Read() pulls from the result queue and returns matching rows.
Maintains the same interface contract.

3. Design decisions
Decision 1: When to parallelize
Only if the underlying reader supports concurrent access, or use a single reader with buffering.
Parallelize the condition evaluation, not the reading.
Decision 2: Ordering strategy
If ORDER BY is present: use sequence numbers and a priority queue.
If no ordering: return results as they complete.
Decision 3: Concurrency control
Limit worker pool size (e.g., CPU count or configurable).
Use semaphores or buffered channels to cap in-flight work.
Decision 4: Error handling
Propagate errors via a separate error channel.
On error, cancel remaining work and return the error.
Decision 5: Context cancellation
Respect context.Context for cancellation.
Cancel all workers when context is done.

4. Implementation steps
Initialize phase
Create buffered channels (input buffer, results queue, error channel).
Start the prefetch goroutine.
Start the worker pool.
Prefetch goroutine
Reads from rowReader.Read() sequentially.
Enqueues rows to the input buffer.
Stops on EOF or error.
Worker pool
Workers pull rows from the input buffer.
Evaluate conditions concurrently.
Send results (row + match status) to the results queue.
Read() method
Pulls from the results queue.
Returns matching rows; skips non-matching ones.
Handles errors and context cancellation.
Cleanup
Close channels when done.
Wait for workers to finish.
Close the underlying reader.

5. Performance considerations
Bottleneck analysis
If condition evaluation is expensive, parallelization helps.
If I/O is the bottleneck, parallelization may not help much.
Memory management
Bound buffer sizes.
Consider backpressure if the consumer is slow.
Tuning
Make worker pool size configurable.
Monitor throughput and adjust.

6. Alternative: simpler approach
If full parallelization is complex:
Keep sequential reading.
Use a small buffer (e.g., 10–100 rows).
Evaluate conditions in batches with goroutines.
Return results in order.

7. Testing strategy
Verify thread safety of the underlying reader.
Test with various condition complexities.
Measure performance vs. sequential version.
Test error propagation and cancellation.
Verify ordering when required.

8. When not to parallelize
Simple conditions (overhead may outweigh benefit).
Small result sets.
If the underlying reader is not thread-safe and buffering doesn’t help.
If memory is constrained.
Summary
Use a pipeline: single prefetch goroutine → worker pool for condition evaluation → result queue → sequential Read(). This parallelizes evaluation while keeping reading sequential and maintaining the interface contract.